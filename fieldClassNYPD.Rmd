---
title: "Data Science as a Field NYPD Exercise"
author: "Charles Fraley"
date: "2022-07-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(forecast)
library(lubridate)
library(mgcv)
library(reshape)
library(stringi)
library(stringr)
```

# Basic Prep
## Load Data and Initial Summary

```{r echo = FALSE}
raw_data <- read.csv(url("https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"))
summary(raw_data)
```

# Data Cleaning
I only need one coordinate source, so I'm going to keep the Latitude and Longitude and get rid of unnecessary items.
```{r echo = FALSE}
clean <- raw_data %>% select(
  -one_of(
    "Lon_Lat","INCIDENT_KEY","X_COORD_CD","Y_COORD_CD",
    "OCCUR_TIME",
    "JURISDICTION_CODE",
    "LOCATION_DESC",
    "STATISTICAL_MURDER_FLAG",
    "PERP_AGE_GROUP",
    "PERP_SEX",
    "PERP_RACE",
    "VIC_AGE_GROUP",
    "VIC_SEX",
    "VIC_RACE"
    ))
#transform(clean, clean$BORO=factor(clean$BORO))
#transform(clean, clean$PRECINCT=factor(clean$PRECINCT))
clean$BORO <- factor(clean$BORO)
clean$PRECINCT <- factor(clean$PRECINCT)
```

Convert dates into corresponding objects.
```{r echo = FALSE}
clean <- transform(clean, OCCUR_DATE = mdy(OCCUR_DATE))
```

Summary to confirm no missing data
```{r echo= FALSE}
summary(clean)
```

# Initial transformation

## Civic Regions and Year
I would like to break down the data into Burroughs and precincts as well as breaking it down by year for an initial view of the trends.

```{r echo= F, eval=T}
clean <- mutate(clean, year=year(OCCUR_DATE))
boros <- select(clean,
  -one_of(
      "PRECINCT",
      "Latitude",
      "Longitude",
      "OCCUR_DATE"
  ))

boro_y <- data.frame(t(table(group_by(boros,year))))
boroplot <- ggplot(boro_y, aes(x=year,y=Freq,col=BORO,group=BORO))+geom_line()
boroplot
```

```{r echo= F, eval=T}
prec <- select(clean,
  -one_of(
      "BORO",
      "Latitude",
      "Longitude",
      "OCCUR_DATE"
  ))
prec_y <- data.frame(t(table(group_by(prec,year))))
precplot <- ggplot(prec_y, aes(x=year,y=Freq,col=PRECINCT,group=PRECINCT))+geom_line()
precplot
```

However these results are more noisy than useful. Additionally this doesn't take into account the size of boros/precincts. As we're focused on change, we'll take another look at proportional change.

$y_0=0$

If $freq_{n-1}==0$, $y_n=\frac{freq_n-freq_{n-1}}{freq_{n-1}}$ 
  else 
    if $freq_n=0$
      $y=0$
    else
      $y=NA$

```{r echo= F, eval=T}
boro_d=data.frame(year=unique(boro_y$year))

for (boro_name in levels(boros$BORO)){
  boro_d[boro_name] <- transmute(
    filter(boro_y, BORO==boro_name),
    boro_name=ifelse(
      lag(Freq)==0,
      ifelse(
        Freq==0,
        0,
        NA
      ),
      (Freq-lag(Freq))/lag(Freq)
  ))
}
p_boro_d <- pivot_longer(boro_d, cols=levels(boros$BORO),names_to = "BORO",values_to="change")
boroplot <- ggplot(p_boro_d, aes(x=year,y=change,col=BORO,group=BORO))+geom_line()
boroplot
```
```{r echo= F, eval=T}
prec_d=data.frame(year=unique(prec_y$year))

for (prec_num in levels(prec$PRECINCT)){
  prec_d[prec_num] <- transmute(
    filter(prec_y, PRECINCT==prec_num),
    prec_num=ifelse(
      lag(Freq)==0,
      ifelse(
        Freq==0,
        0,
        NA
      ),
      (Freq-lag(Freq))/lag(Freq)
  ))
}
p_prec_d <- pivot_longer(prec_d, cols=levels(prec$PRECINCT),names_to = "PRECINCT",values_to="change")
precplot <- ggplot(p_prec_d, aes(x=year,y=change,col=PRECINCT,group=PRECINCT))+geom_line()
precplot
```

## Control for city wide changes

For trying to isolate changes for further investigation it would probably be useful to account for the city wide changes.

```{r echo= F, eval=T}
all <- select(clean,"year")

all_y <- data.frame(t(table(group_by(all,year)))) %>% select(-(Var1))

all_d <- mutate(
  all_y,
  change=ifelse(
    lag(Freq)==0,
    ifelse(
      Freq==0,
      0,
      NA
    ),
    (Freq-lag(Freq))/lag(Freq)
  )
)
allplot <- ggplot(all_d)+aes(x=year,y=change, group=1)+geom_line()
allplot
```

So .change at the boro and precinct level - the change at the city level:
```{r echo= F, eval=T}
prec_d_norm <- data.frame(year=prec_d$year)
for (prec_num in levels(prec$PRECINCT)){
  prec_d_norm[prec_num] <- prec_d[prec_num]-all_d$change
}
p_prec_n_d <- pivot_longer(
  prec_d_norm, 
  cols=levels(prec$PRECINCT),
  names_to = "PRECINCT",
  values_to="change"
  )
precplot <- ggplot(
  p_prec_n_d, 
  aes(x=year,y=change,col=PRECINCT,group=PRECINCT))+geom_line()
# precplot<- precplot+geom_line(all_d, aes(x=year,y=change,color="black"))
precplot
```
```{r echo= F, eval=T}
boro_d_norm <- data.frame(year=boro_d$year)
for (boro_name in levels(boros$BORO)){
  boro_d_norm[boro_name] <- boro_d[boro_name]-all_d$change
}
p_boro_n_d <- pivot_longer(
  boro_d_norm, 
  cols=levels(boros$BORO),
  names_to = "BORO",
  values_to="change"
  )
boroplot <- ggplot(
  p_boro_n_d, 
  aes(x=year,y=change,col=BORO,group=BORO))+geom_line()
boroplot
```

# Conclusion

## Additional Questions
Second derivative/change in trend analysis
Use of higher resolution combined with periodic analysis 
Lat/Lon analysis
## Assumptions

### Personal

### Methodological

Assumption that taking years as a whole should remove periodic changes and illuminate longer term changes

### Data

\newpage

# Appendix: Discarded Initial Exploration

## Data Cleaning
I only need one coordinate source, so I'm going to keep the Latitude and Longitude and get rid of unnecessary items.
```{r echo = FALSE}
clean <- raw_data %>% select(-one_of("LON_LAT","INCIDENT_KEY","X_COORD_CD","Y_COORD_CD"))
clean <- transform(clean, OCCUR_DATE = mdy(OCCUR_DATE))
```

Statistical murder flag should be binary not a string
```{r echo = FALSE}
clean <- transform(clean,STATISTICAL_MURDER_FLAG = (STATISTICAL_MURDER_FLAG=="true"))
```
## Basic Transformations
Creating 2 column table of dates vs num of shootings. Displaying with basic linear model.

```{r echo = FALSE}
by_day <- table(clean$OCCUR_DATE)
by_day_df <- data.frame(by_day)
colnames(by_day_df) <- c("date","shootings")

by_day_df <- transform(by_day_df,date=as.POSIXct(date, origin = "1970-01-01"))
lmod <- lm(date ~ shootings, data = by_day_df)
lmod
shotplot <- ggplot(by_day_df)+geom_point(
  data=by_day_df,
  aes(x=date, y=shootings))+
  geom_smooth(data=by_day_df, method='lm', aes(x=date, y=shootings))
shotplot
```

## Analysis

### Modelling
Linear model is not really useful, trying an alternative fit based on a custom periodic model:

$a*sin(\frac{date}{b}+c)+d*sin(\frac{date}{e}+f)+g*date+h$

```{r echo=F}
date_to_int <- function(end_date) {
  result<-as.numeric(difftime(end_date,ymd("2006-01-01"),units="days"))
}
```
```{r echo=F}
nlc <- nls.control(maxiter = 1000)
custommod<-nls(
  shootings ~ a*sin(date_to_int(date)/b+c)+d*sin(date_to_int(date)/e+f)+g*date_to_int(date)+h,
  data=by_day_df,
  control=nlc,
  start=list(a=30,b=300,c=0,d=10,e=150,f=0,g=0,h=10)
  )

summary(custommod)
```
```{r echo=F, eval=T}
prediction <- predict(custommod, by_day_df$date)
prediction <- data.frame(by_day_df$date, prediction)
colnames(prediction) <- c("date","shootings")
head(prediction)
```
```{r echo=F, eval=T}
shotplot <- shotplot + 
  geom_line(data=prediction,aes(x=date, y=shootings), color="red")
#  stat_function(
#    fun=function(x) custommod["a"]*sin(date_to_int(x)/custommod["b"]+
#                                         custommod["c"])) #+d*sin(date_to_int(x)/e+f)+g*date_to_int(x)+h)
shotplot
```
### Periodic examination

```{r echo=F, eval=T}
class(by_day_df$date)
```
```{r echo=F, eval=F}
# split <- separate(by_day_df$date, c('date1','date2'))
by_month <-group_by(month=floor_date(by_day_df$date, 'month'))
summary(by_month)
```

### Geographic Examination
```{r echo=T, eval=F}
lat_lon <- data.frame(stri_extract_all_regex(clean$Lon_Lat,'-?\\d+\\.\\d+'))
melted_coord <-melt(lat_lon)
```
### Additional Questions Prompted

A future angle for investigation may be to find locations where there has been an increase in shootings.
Additionally, it would be useful to look specifically for periodic patterns especially those that can be localized. 
Finally it would be good to correlate changes to various policy decisions and changes in the city. This does bring up a lot of complications. Correlation is not causation etc.

## Conclusion

There appears to be a general downward trend but the amount of noise and looseness of the fit does not suggest confidence.

### Bias Sources

#### Data Source
Selection bias based on where shootings are reported to police.

Information is not very generalizable as New York is a very unique location.

#### Personal bias
Lack of knowledge about New York. 
The aimlessness and lack of preexisting knowledge about New York lead me to make rather general analysis rather than a more useful breakdown towards a defined goal.

#### Bias mitigation

My approach to this data has been largely exploratory. 
I did not really draw much in the way of conclusions. 
Going forward a way to mitigate bias may be to look to others for potential questions and hypotheses.
This may prevent all my answers coming from my pre-existing beliefs determining the questions.
My exploration was partially removed from my own feelings on the subject by my focus being by necessity technical.
I am an R novice so my goals were largely around handling basic R tasks.
